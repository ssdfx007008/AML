{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read, np-ifying now\n",
      "\n",
      "(1500, 12419)\n"
     ]
    }
   ],
   "source": [
    "import math, random, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "\n",
    "N_Docs = 1500 \n",
    "N_Words = 12419\n",
    "Nonzero_Counts = 746316\n",
    "raw_data = pd.read_csv('data_processed.txt', delimiter = ' ')\n",
    "vocab = pd.read_csv('vocab.nips.txt')\n",
    "\n",
    "print('data read, np-ifying now')\n",
    "\n",
    "\n",
    "data = np.zeros( (N_Docs, N_Words)) \n",
    "for i in tqdm_notebook(range(Nonzero_Counts)):\n",
    "    data[raw_data['Doc'][i]-1][raw_data['Word'][i]-1]=raw_data['Count'][i]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "#pg 234 in text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFilesE\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:4265: FutureWarning: in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integer\n",
      "  \"as boolean index instead of casting it to integer\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 12418) 12418\n"
     ]
    }
   ],
   "source": [
    "vocab_arr = vocab.values\n",
    "Word_Totals = np.zeros(N_Words)\n",
    "for i in tqdm_notebook(range(N_Words)):\n",
    "    Word_Totals[i] = np.sum(data[:, i])\n",
    "    \n",
    "zeroes = not np.nonzero(Word_Totals)\n",
    "\n",
    "data = np.delete(data, zeroes, axis=1)\n",
    "Word_Totals = np.delete(Word_Totals, zeroes, axis=0)\n",
    "vocab_arr = np.delete(vocab_arr, zeroes, axis = 0)\n",
    "N_Words = data.shape[1]\n",
    "print(data.shape, N_Words)\n",
    "\n",
    "\n",
    "#resources\n",
    "#pg 234 in text\n",
    "#http://www.cs.columbia.edu/~jebara/4771/tutorials/multinomial.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://en.wikipedia.org/wiki/Multinomial_distribution\n",
    "#n, the number of trials is the sum of a word's total appearances \n",
    "#word is a row off of the doc array, with each index corresponding to a word, and the value there being the count\n",
    "#params is the probability of seeing a certain word - this is precalculated in the main flow. it is the {p1,p2,...pn}\n",
    "\n",
    "# def logsumexp(X):\n",
    "#     x_max = X.max(1)\n",
    "#     return x_max + np.log(np.exp(X - x_max[:, None]).sum(1))\n",
    "# def logfact(X):\n",
    "#     ret = 0\n",
    "#     while (X > 0):\n",
    "#         ret += math.log(X)\n",
    "#         X-=1\n",
    "#     return ret\n",
    "# def multinomial_logpdf(doc, param):\n",
    "#     log_nfact =logfact(np.sum(doc))\n",
    "#     log_xis = 0\n",
    "#     log_probs = 0\n",
    "#     for i in range(N_Words):\n",
    "#         if doc[i] > 0:\n",
    "#             log_xis += logfact(doc[i])\n",
    "#             log_probs += math.log(param[i]) *doc[i]\n",
    "# #     print(log_nfact, log_probs, log_xis)\n",
    "#     return np.exp(log_nfact + log_probs - log_xis)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Assign_Labels(data, Doc_Label_Weights, topic_params, pi):\n",
    "    tmp = np.zeros(30)\n",
    "    for i in tqdm_notebook(range(N_Docs)):\n",
    "        for j in range(30):\n",
    "            tmp[j] = np.sum(data[i,:] * np.log(topic_params[j, :]))+ np.log(pi[j])\n",
    "            max = np.amax(tmp)\n",
    "        denom = 0\n",
    "        for j in range(30):\n",
    "            denom += np.exp(tmp[j] - max)\n",
    "        for j in range(30):\n",
    "            num = np.exp( \n",
    "                np.sum(data[i,:] * np.log(topic_params[j,:]))\n",
    "                + np.log(pi[j])-max\n",
    "                      )\n",
    "            Doc_Label_Weights[i][j] = num/denom\n",
    "            \n",
    "            \n",
    "            \n",
    "def estimate_params(data,Doc_Label_Weights, topic_params, pi):\n",
    "    for i in tqdm_notebook(range(30)):\n",
    "        p_num = np.full((N_Words), .05)\n",
    "        p_denom = np.zeros(N_Words)\n",
    "        for j in range(N_Docs):\n",
    "            p_num += data[j] * Doc_Label_Weights[j, i]\n",
    "            p_denom += np.dot(data[j], np.ones(N_Words) * Doc_Label_Weights[j][i]  )\n",
    "        topic_params[i, :] = p_num/p_denom\n",
    "        \n",
    "        new_pi = 0\n",
    "        for j in range(N_Docs):\n",
    "            new_pi += Doc_Label_Weights[j][i]\n",
    "        pi[i] = new_pi/N_Docs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "setup completed\n"
     ]
    }
   ],
   "source": [
    "topic_params = np.random.rand(30, N_Words)\n",
    "\n",
    "Doc_Label_Weights = np.random.rand(N_Docs,30) #w_ij values for each word x topic combo [DDCUMENT][TOPIC]\n",
    "for i in range(N_Docs):\n",
    "    Doc_Label_Weights[i,:] /= np.sum(Doc_Label_Weights[i])\n",
    "\n",
    "pi = np.zeros(30)\n",
    "estimate_params(data,Doc_Label_Weights, topic_params, pi)\n",
    "\n",
    "print(\"setup completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Assign_Labels(data, Doc_Label_Weights, topic_params, pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimate_params(data,Doc_Label_Weights, topic_params,pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iter 0: 0.0104759484805\n",
      "\n",
      "\n",
      "iter 1: 0.00311727306123\n",
      "\n",
      "\n",
      "iter 2: 0.00221501257985\n",
      "\n",
      "\n",
      "iter 3: 0.00106789544856\n",
      "\n",
      "\n",
      "iter 4: 0.00117866449244\n",
      "\n",
      "\n",
      "iter 5: 0.000898133887637\n",
      "\n",
      "\n",
      "iter 6: 0.000829155958494\n",
      "\n",
      "\n",
      "iter 7: 0.000932852885421\n",
      "\n",
      "\n",
      "iter 8: 0.000762669841602\n",
      "\n",
      "\n",
      "iter 9: 0.00178196889358\n",
      "\n",
      "\n",
      "iter 10: 0.00162494986379\n",
      "\n",
      "\n",
      "iter 11: 0.000935222919904\n",
      "\n",
      "\n",
      "iter 12: 0.00092284002594\n",
      "\n",
      "\n",
      "iter 13: 0.000938823419857\n",
      "\n",
      "\n",
      "iter 14: 7.44941296668e-06\n"
     ]
    }
   ],
   "source": [
    "old_pi = np.copy(pi)\n",
    "eps = .0001\n",
    "\n",
    "for i in range(100):\n",
    "    Assign_Labels(data, Doc_Label_Weights, topic_params,pi)\n",
    "    estimate_params(data,Doc_Label_Weights, topic_params,pi)\n",
    "    d = np.linalg.norm(old_pi - pi)\n",
    "    print(\"iter \"+str(i) + \": \" + str(d))\n",
    "    if(np.linalg.norm(d) < eps):\n",
    "        break\n",
    "    old_pi = np.copy(pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02471634  0.04560501  0.02073199  0.04972014  0.0314425   0.01936878\n",
      "  0.02477817  0.03942466  0.04885754  0.03358025  0.02228758  0.02271804\n",
      "  0.04007709  0.02343793  0.04273066  0.01960418  0.06286617  0.04206085\n",
      "  0.05175153  0.0229833   0.04083399  0.02280696  0.02084974  0.01174772\n",
      "  0.0448718   0.05447857  0.02127421  0.02281421  0.03480378  0.03677629]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqwsI2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f31d09ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graphing time\n",
    "#Produce a graph showing, for each topic, the probability with which the topic is selected.\n",
    "\n",
    "Topic_Totals = np.zeros(30)\n",
    "#Word_Labels == i\n",
    "for i in range(30):\n",
    "    for j in range(N_Docs):\n",
    "        Topic_Totals[i] += Doc_Label_Weights[j][i]\n",
    "Topic_Totals /= np.sum(Topic_Totals)\n",
    "print(Topic_Totals)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.bar(left = range(0,30), height = Topic_Totals)\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.pie(Topic_Totals)\n",
    "# I thought the pie chart might be amusing at least, it's not even that. Turns out 30 is too many ways to split a pizza\n",
    "plt.show(block = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Topic Number, ', 'Most Common, ', '2nd Most Common, 3rd, ', '4th', '5th', '6th', '7th', '8th', '9th', '10th']\n",
      "1,  [\"['matsuoka']\", \"['finder']\", \"['classifies']\", \"['van']\", \"['terman']\", \"['noiseless']\", \"['experimental']\", \"['testable']\", \"['machinery']\", \"['meaning']\"]\n",
      "2,  [\"['fifteen']\", \"['expertise']\", \"['stephen']\", \"['noncausal']\", \"['systematic']\", \"['dimensionalities']\", \"['patterned']\", \"['approached']\", \"['distances']\", \"['nodel']\"]\n",
      "3,  [\"['centered']\", \"['processor']\", \"['noiseless']\", \"['rated']\", \"['stressed']\", \"['componential']\", \"['construct']\", \"['distributional']\", \"['god']\", \"['visualisation']\"]\n",
      "4,  [\"['probable']\", \"['experimental']\", \"['languages']\", \"['phonemes']\", \"['feb']\", \"['letterform']\", \"['sequencer']\", \"['pointed']\", \"['training']\", \"['formal']\"]\n",
      "5,  [\"['connectionism']\", \"['linearities']\", \"['recurrently']\", \"['localised']\", \"['expertise']\", \"['translate']\", \"['foster']\", \"['noiseless']\", \"['generalize']\", \"['informational']\"]\n",
      "6,  [\"['gausstan']\", \"['cellular']\", \"['cases']\", \"['noiseless']\", \"['formal']\", \"['performances']\", \"['log2']\", \"['localised']\", \"['largely']\", \"['noncausal']\"]\n",
      "7,  [\"['class2']\", \"['processor']\", \"['layered']\", \"['rated']\", \"['labeled']\", \"['pointed']\", \"['distributional']\", \"['davies']\", \"['realisation']\", \"['spikes']\"]\n",
      "8,  [\"['classified']\", \"['systematic']\", \"['informational']\", \"['mixtures']\", \"['posteriori']\", \"['outseg']\", \"['log2']\", \"['hierar']\", \"['stephen']\", \"['patterned']\"]\n",
      "9,  [\"['meaning']\", \"['ordered']\", \"['class2']\", \"['enforce']\", \"['theoretic']\", \"['propel']\", \"['gradual']\", \"['classifies']\", \"['dimensional']\", \"['stephen']\"]\n",
      "10,  [\"['patterned']\", \"['cases']\", \"['header']\", \"['layered']\", \"['methodologies']\", \"['probable']\", \"['componential']\", \"['losses']\", \"['rbm']\", \"['training']\"]\n",
      "11,  [\"['van']\", \"['recherche']\", \"['distributional']\", \"['linearities']\", \"['localised']\", \"['hierar']\", \"['segmenta']\", \"['erties']\", \"['noiseless']\", \"['responses']\"]\n",
      "12,  [\"['vectorial']\", \"['speechreading']\", \"['net32k']\", \"['fixes']\", \"['testable']\", \"['training']\", \"['cases']\", \"['linearities']\", \"['sequencer']\", \"['largely']\"]\n",
      "13,  [\"['meaning']\", \"['trees']\", \"['validatory']\", \"['largely']\", \"['approached']\", \"['tat']\", \"['crosscorrelation']\", \"['vectorial']\", \"['controllable']\", \"['patterned']\"]\n",
      "14,  [\"['winning']\", \"['voltages']\", \"['ordered']\", \"['activ']\", \"['dynamical']\", \"['sized']\", \"['analyte']\", \"['lowe']\", \"['computational']\", \"['curried']\"]\n",
      "15,  [\"['ordered']\", \"['iterative']\", \"['variances']\", \"['matsuoka']\", \"['approached']\", \"['largely']\", \"['localised']\", \"['sampled']\", \"['hierar']\", \"['linear']\"]\n",
      "16,  [\"['imaginary']\", \"['feb']\", \"['regional']\", \"['synaptic']\", \"['contrasted']\", \"['curried']\", \"['responsibilities']\", \"['surrounded']\", \"['synaptically']\", \"['algorithmic']\"]\n",
      "17,  [\"['optimality']\", \"['patterned']\", \"['hierar']\", \"['dimensional']\", \"['callaway']\", \"['largely']\", \"['ordered']\", \"['theoretic']\", \"['sized']\", \"['conceptual']\"]\n",
      "18,  [\"['priori']\", \"['ordered']\", \"['dent']\", \"['noncausal']\", \"['mapped']\", \"['linearities']\", \"['probable']\", \"['dynamical']\", \"['matsuoka']\", \"['terman']\"]\n",
      "19,  [\"['paperclip']\", \"['decisive']\", \"['row']\", \"['iterative']\", \"['predictive']\", \"['markovian']\", \"['finitely']\", \"['translate']\", \"['approached']\", \"['adaptively']\"]\n",
      "20,  [\"['feedfor']\", \"['layered']\", \"['testable']\", \"['class2']\", \"['classifies']\", \"['architectures']\", \"['rob']\", \"['linearities']\", \"['activ']\", \"['representational']\"]\n",
      "21,  [\"['corti']\", \"['erties']\", \"['tunley']\", \"['methodologies']\", \"['fight']\", \"['tat']\", \"['numbered']\", \"['simpler']\", \"['algorithmic']\", \"['trajec']\"]\n",
      "22,  [\"['iter']\", \"['known']\", \"['kerr']\", \"['noiseless']\", \"['imaginary']\", \"['directional']\", \"['subjected']\", \"['informational']\", \"['salient']\", \"['parameterised']\"]\n",
      "23,  [\"['correlational']\", \"['optimality']\", \"['singly']\", \"['cases']\", \"['filterbank']\", \"['signatures']\", \"['equi']\", \"['pointed']\", \"['stephen']\", \"['approached']\"]\n",
      "24,  [\"['imagery']\", \"['retinal']\", \"['spacecraft']\", \"['stephen']\", \"['adapted']\", \"['sensor']\", \"['stinchcombe']\", \"['stimulus']\", \"['rated']\", \"['classified']\"]\n",
      "25,  [\"['processor']\", \"['linearities']\", \"['weighted']\", \"['temporally']\", \"['cortices']\", \"['equi']\", \"['spacecraft']\", \"['excite']\", \"['unitary']\", \"['features']\"]\n",
      "26,  [\"['singly']\", \"['synapses']\", \"['mapped']\", \"['erties']\", \"['bite']\", \"['eyes']\", \"['memoryless']\", \"['controllable']\", \"['performances']\", \"['pointed']\"]\n",
      "27,  [\"['hierar']\", \"['processor']\", \"['tat']\", \"['algorithmic']\", \"['performances']\", \"['positional']\", \"['pointed']\", \"['flower']\", \"['training']\", \"['robotic']\"]\n",
      "28,  [\"['rulebase']\", \"['layered']\", \"['weighted']\", \"['approached']\", \"['activ']\", \"['noncausal']\", \"['ordered']\", \"['spacecraft']\", \"['testable']\", \"['net32k']\"]\n",
      "29,  [\"['testable']\", \"['classified']\", \"['hierar']\", \"['locative']\", \"['visualisation']\", \"['targeted']\", \"['matsuoka']\", \"['localised']\", \"['regressive']\", \"['hummel']\"]\n",
      "30,  [\"['simulator']\", \"['linearities']\", \"['associator']\", \"['fifteen']\", \"['representational']\", \"['voltages']\", \"['brainard']\", \"['connectionism']\", \"['erties']\", \"['parallelism']\"]\n"
     ]
    }
   ],
   "source": [
    "Topic_TopTens = np.zeros((30,10),dtype = np.int32)\n",
    "for i in range(30):\n",
    "#     ten = np.argpartition(topic_params[i], N_Docs - 10, axis = 0)[N_Docs-11:N_Docs-1]\n",
    "# #     print(ten)\n",
    "#     print(np.sort(topic_params[i]))\n",
    "#     ten_sorted = np.argsort(topic_params[i][ten])#sorts in ASCENDING order\n",
    "#     print(topic_params[i][ten])\n",
    "# We were doing argpartition + trying to sort the remainder (returning indices sorted on the values of those indices in another array gets messy), but it's really not much faster than just finding the max 10 times.\n",
    "    for j in range(10):\n",
    "        Topic_TopTens[i][j] = np.argmax(topic_params[i, :])\n",
    "        topic_params[i][np.argmax(topic_params[i, :]) ] = 0\n",
    "        \n",
    "# for i in range(30):\n",
    "#     print(\"Topic Number: \" + str(i))\n",
    "#     for j in range(9,-1,-1):\n",
    "#         print(str(j) +' : '+ vocab['a2i'][Topic_TopTens[i][j]])\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# print(Topic_TopTens)\n",
    "# from tabulate import tabulate\n",
    "print(['Topic Number, ','Most Common, ', \"2nd Most Common, \" + \"3rd, \"] + [str(i)+'th' for i in range(4,11)])\n",
    "for i in range(30):\n",
    "    print(str(i+1) + ', ' , [str(vocab_arr[j]) for j in Topic_TopTens[i]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "036b188904874ba49d98d2fae5e25755": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "0623a6098cd24a3ea00d078e26ecfc1c": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "0c15be42ed3f4ed89a957102313a56b5": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "139c5376906d45b99a3a334bc00ea08a": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "14416a06baaf456e82ad642cbd8a64a4": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "17c712b4ffeb4413afac8d1bac657d47": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "2202568bc21744be9776a97d9bb2d85d": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "35ac52141507483099c8d5f2ea550a5e": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "4a1078a67465458b9bceb8cd142165a1": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "4f52b67e81bd48ada167dde1e22b24fb": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "544315ea9eb741a285066ee7bb6aad9c": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "580daa6e2bc446f981f48b02ee1b7c28": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "5b37ef92b3d44630b2918135bc878aa7": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "614cae0751cc4cfcbe78110320c8a8b6": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "689d48571bfc4b3cabddff15c43ab5e2": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "6e6df25c97384571b85e770a96d932fb": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "7bef261c75db4275b72bf73118233bbf": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "80c2517b382a4fa0861a5ae68f6fd9f1": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "823a093526a14c38ba39914482c8040c": {
     "views": [
      {
       "cell_index": 0
      }
     ]
    },
    "8421ab4afe534cf9a5a637a579b4c58a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "996a8fa76cd041be9f4f4006ecafbd15": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "99d642d3a01348298c8a403aed75a7d2": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "a86592241cce471e9e31a227bf1523c0": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "a9f0bb6c23c4410eb9fa39bddcc6ad5a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "b43fa19a5b5b47b0af3d9180135b0667": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "be01c12185af4178a07e68d4c9d07bb9": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "bebb13f56c6947a999c1c984262490bf": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "cf63f60d6e294b3a855bd9206b98ca8c": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "d39e2516b026453f8bd64f6736ec26ff": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "dfc0433359e64621a47dbc19eead2ead": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "ef2e07c178814af9a8e83cb26cf4e02d": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f4bf146127d1450bbe122eea0a1ab914": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f5fb684d71014d55a1e3e73feaa3af8a": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "f741b9699f2e4bc286d82c202d3a2779": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "fb1a99498e194b64ad6c880976e58493": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
